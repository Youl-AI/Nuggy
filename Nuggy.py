import streamlit as st
import os
import torch
from torchvision import transforms
from PIL import Image
import numpy as np
import cv2
import io

# ---------------------------------------------------------
# ğŸ¨ [UI ì„¤ì •] í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
# ---------------------------------------------------------
st.set_page_config(
    page_title="NuGgy Master - AI ë°°ê²½ ì œê±°",
    page_icon="ğŸ°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------------------------------------------
# ğŸ¨ [ì»¤ìŠ¤í…€ CSS] ì›¹í˜ì´ì§€ë¥¼ ì˜ˆì˜ê²Œ ê¾¸ë¯¸ê¸° ìœ„í•œ ìŠ¤íƒ€ì¼
# ---------------------------------------------------------
st.markdown("""
    <style>
    /* ë©”ì¸ íƒ€ì´í‹€ í°íŠ¸ ë° ì •ë ¬ */
    .main-title {
        font-size: 3rem;
        font-weight: 700;
        color: #2E86C1;
        text-align: center;
        margin-bottom: 10px;
    }
    .sub-title {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 30px;
    }
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í…€ */
    div.stButton > button:first-child {
        background-color: #2E86C1;
        color: white;
        font-size: 18px;
        font-weight: bold;
        border-radius: 10px;
        padding: 10px 20px;
        border: none;
        width: 100%;
    }
    div.stButton > button:first-child:hover {
        background-color: #1B4F72;
        color: white;
    }
    /* íŒŒì¼ ì—…ë¡œë” ë°•ìŠ¤ ìŠ¤íƒ€ì¼ */
    .stFileUploader {
        border: 2px dashed #2E86C1;
        border-radius: 10px;
        padding: 20px;
    }
    /* ê²°ê³¼ ì´ë¯¸ì§€ ì»¨í…Œì´ë„ˆ */
    .result-container {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 15px;
        text-align: center;
    }
    </style>
    """, unsafe_allow_html=True)

# ---------------------------------------------------------
# ğŸ› ï¸ [ì„¤ì •] ëª¨ë¸ ë° íŒŒë¼ë¯¸í„°
# ---------------------------------------------------------
MODEL_PATH = "./checkpoints/best_finetuned_model.pth"
IMG_SIZE = 1024
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# ê¸°ë³¸ê°’ ì„¤ì •
NOISE_CUTOFF = 0.2
MIN_AREA_RATIO = 0.001
GAMMA = 0.5
GUIDED_R = 4
GUIDED_EPS = 1e-4
USE_TTA = True

# ---------------------------------------------------------
# ğŸ§© í•¨ìˆ˜ ì •ì˜ (ëª¨ë¸ ë¡œë“œ & ì•Œê³ ë¦¬ì¦˜)
# ---------------------------------------------------------
@st.cache_resource
def load_model():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root_path = os.path.join(current_dir, 'DIS')
    import sys
    if project_root_path not in sys.path:
        sys.path.append(project_root_path)

    try:
        from models.isnet import ISNetDIS
        model = ISNetDIS().to(DEVICE)
        if not os.path.exists(MODEL_PATH):
            return None
        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        model.eval()
        return model
    except Exception as e:
        return None

def guided_filter(I, p, r, eps):
    ksize = (2 * r + 1, 2 * r + 1)
    mean_I = cv2.boxFilter(I, cv2.CV_32F, ksize)
    mean_p = cv2.boxFilter(p, cv2.CV_32F, ksize)
    mean_Ip = cv2.boxFilter(I * p, cv2.CV_32F, ksize)
    mean_II = cv2.boxFilter(I * I, cv2.CV_32F, ksize)
    cov_Ip = mean_Ip - mean_I * mean_p
    var_I = mean_II - mean_I * mean_I
    a = cov_Ip / (var_I + eps)
    b = mean_p - a * mean_I
    mean_a = cv2.boxFilter(a, cv2.CV_32F, ksize)
    mean_b = cv2.boxFilter(b, cv2.CV_32F, ksize)
    q = mean_a * I + mean_b
    return q

def run_inference(model, image, cutoff, gamma, guided_r, guided_eps):
    orig_w, orig_h = image.size
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
    ])
    
    # TTA Inference
    with torch.no_grad():
        img_tensor = transform(image).unsqueeze(0).to(DEVICE)
        preds_1 = model(img_tensor)
        while isinstance(preds_1, (list, tuple)): preds_1 = preds_1[0]
        final_mask = torch.sigmoid(preds_1)

        if USE_TTA:
            img_flip = image.transpose(Image.FLIP_LEFT_RIGHT)
            img_flip_tensor = transform(img_flip).unsqueeze(0).to(DEVICE)
            preds_2 = model(img_flip_tensor)
            while isinstance(preds_2, (list, tuple)): preds_2 = preds_2[0]
            mask_2 = torch.sigmoid(preds_2)
            mask_2 = torch.flip(mask_2, dims=[3]) 
            final_mask = (final_mask + mask_2) / 2.0

    pred_mask = final_mask.squeeze().cpu().numpy()
    if pred_mask.max() != pred_mask.min():
        pred_mask = (pred_mask - pred_mask.min()) / (pred_mask.max() - pred_mask.min())

    # Guided Filter
    src_img_pil = image.resize((IMG_SIZE, IMG_SIZE)).convert("L")
    src_img = np.array(src_img_pil).astype(np.float32) / 255.0
    guidance_mask = pred_mask.astype(np.float32)
    refined_mask = guided_filter(I=src_img, p=guidance_mask, r=guided_r, eps=guided_eps)
    pred_mask = refined_mask

    # Island Removal
    pred_mask[pred_mask < cutoff] = 0.0
    temp_mask = (pred_mask * 255).astype(np.uint8)
    contours, _ = cv2.findContours(temp_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if contours:
        clean_mask = np.zeros_like(temp_mask)
        total_area = temp_mask.shape[0] * temp_mask.shape[1]
        min_area = total_area * MIN_AREA_RATIO
        for contour in contours:
            if cv2.contourArea(contour) > min_area:
                cv2.drawContours(clean_mask, [contour], -1, 255, thickness=cv2.FILLED)
        pred_mask = np.where(clean_mask > 0, pred_mask, 0.0)

    # Gamma & Finalize
    pred_mask = np.power(pred_mask, gamma)
    pred_mask[pred_mask > 0.95] = 1.0
    
    pred_mask = (pred_mask * 255).astype(np.uint8)
    mask_img = Image.fromarray(pred_mask).convert("L")
    mask_img = mask_img.resize((orig_w, orig_h), resample=Image.BILINEAR)
    
    result_img = image.copy()
    result_img.putalpha(mask_img)
    
    return result_img, mask_img

# ---------------------------------------------------------
# ğŸ–¥ï¸ ë©”ì¸ UI ë ˆì´ì•„ì›ƒ
# ---------------------------------------------------------

# 1. í—¤ë” ì„¹ì…˜
st.markdown('<div class="main-title">ğŸ° NuGgy Master</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">AI Powered Background Removal Tool | Fine-tuned IS-Net</div>', unsafe_allow_html=True)

# 2. ì‚¬ì´ë“œë°” (ì˜µì…˜ ì„¤ì •)
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/4472/4472515.png", width=80)
    st.title("Settings")
    st.markdown("---")
    
    st.subheader("ğŸ¨ ë°°ê²½ í•©ì„± ì˜µì…˜")
    bg_color = st.color_picker("ë°°ê²½ìƒ‰ ì„ íƒ (í•©ì„±ìš©)", "#FFFFFF")
    
    st.markdown("---")
    st.subheader("âš™ï¸ ê³ ê¸‰ ì„¤ì • (Tuning)")
    
    with st.expander("ì „ë¬¸ê°€ ì˜µì…˜ í¼ì¹˜ê¸°"):
        st.info("ê²°ê³¼ê°€ ë§ˆìŒì— ì•ˆ ë“¤ë©´ ì¡°ì ˆí•˜ì„¸ìš”.")
        val_cutoff = st.slider("ë…¸ì´ì¦ˆ ì œê±° ê°•ë„", 0.0, 0.1, NOISE_CUTOFF, 0.01, help="ê°’ì´ í´ìˆ˜ë¡ ë°°ê²½ì´ ê¹¨ë—í•´ì§€ì§€ë§Œ, í„¸ ëì´ ì˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        val_gamma = st.slider("ì„ ëª…ë„ ë³´ì •", 0.1, 1.0, GAMMA, 0.1, help="ê°’ì´ ì‘ì„ìˆ˜ë¡ í”¼ì‚¬ì²´ê°€ ë‘êº¼ì›Œì§‘ë‹ˆë‹¤.")
        val_guided_r = st.slider("í„¸ ë””í…Œì¼ ë°˜ê²½", 1, 10, GUIDED_R, 1, help="í„¸ì´ ë­‰ê°œì§€ë©´ ì´ ê°’ì„ ì¤„ì´ì„¸ìš”.")

# 3. ëª¨ë¸ ë¡œë“œ
model = load_model()

if model is None:
    st.error("ğŸš¨ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! `checkpoints` í´ë”ì— ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    # 4. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜
    uploaded_file = st.file_uploader("", type=["jpg", "png", "jpeg"], help="ì—¬ê¸°ì— ì´ë¯¸ì§€ë¥¼ ë“œë˜ê·¸ ì•¤ ë“œë¡­í•˜ì„¸ìš”.")

    if uploaded_file is not None:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(uploaded_file).convert("RGB")
        
        # 2ë‹¨ ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("#### ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€")
            st.image(image, use_column_width=True, caption="Original Image")

        with col2:
            st.markdown("#### âœ¨ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
            
            # [ë²„íŠ¼] ì‹¤í–‰ íŠ¸ë¦¬ê±°
            if st.button("ë°°ê²½ ì œê±° ì‹¤í–‰ (Start Process)", type="primary"):
                with st.spinner("AIê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ°"):
                    try:
                        res_img, mask_img = run_inference(
                            model, image, val_cutoff, val_gamma, val_guided_r, GUIDED_EPS
                        )
                        
                        # ì„¸ì…˜ ìƒíƒœì— ì €ì¥ (ìƒˆë¡œê³ ì¹¨ ë°©ì§€)
                        st.session_state['res_img'] = res_img
                        st.session_state['mask_img'] = mask_img
                        
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

            # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë³´ì—¬ì£¼ê¸°
            if 'res_img' in st.session_state:
                final_res = st.session_state['res_img']
                final_mask = st.session_state['mask_img']
                
                # íƒ­ ë ˆì´ì•„ì›ƒ (ì—¬ê¸°ê°€ í•µì‹¬!)
                tab1, tab2, tab3 = st.tabs(["â¬œ íˆ¬ëª… ë°°ê²½", "ğŸ¨ ì»¬ëŸ¬ ë°°ê²½ í•©ì„±", "âš«ï¸ ë§ˆìŠ¤í¬(Mask)"])
                
                with tab1:
                    st.image(final_res, use_column_width=True, caption="Transparent Background")
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    buf = io.BytesIO()
                    final_res.save(buf, format="PNG")
                    st.download_button("ğŸ“¥ íˆ¬ëª… PNG ë‹¤ìš´ë¡œë“œ", buf.getvalue(), "nuggy_transparent.png", "image/png")

                with tab2:
                    # ë°°ê²½ í•©ì„± ë¡œì§
                    bg_layer = Image.new("RGB", final_res.size, bg_color)
                    comp_img = Image.alpha_composite(bg_layer.convert("RGBA"), final_res)
                    st.image(comp_img, use_column_width=True, caption=f"Background Color: {bg_color}")
                    
                    # í•©ì„± ë‹¤ìš´ë¡œë“œ
                    buf_c = io.BytesIO()
                    comp_img.convert("RGB").save(buf_c, format="JPEG")
                    st.download_button("ğŸ“¥ í•©ì„±ëœ JPG ë‹¤ìš´ë¡œë“œ", buf_c.getvalue(), "nuggy_color.jpg", "image/jpeg")

                with tab3:
                    st.image(final_mask, use_column_width=True, caption="Segmentation Mask")

    else:
        # íŒŒì¼ ì—†ì„ ë•Œ ì•ˆë‚´ ë¬¸êµ¬
        st.info("â˜ï¸ ìœ„ ë°•ìŠ¤ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë°°ê²½ ì œê±°ê°€ ì‹œì‘ë©ë‹ˆë‹¤.")
        
        # ë°ëª¨ìš© ê°¤ëŸ¬ë¦¬ (ë¹ˆ ê³µê°„ ì±„ìš°ê¸°)
        st.markdown("---")
        st.markdown("#### ğŸ‘€ ì˜ˆì‹œ ê²°ê³¼")
        c1, c2, c3 = st.columns(3)
        c1.markdown("ğŸ‡ **ë™ë¬¼ì˜ ë¯¸ì„¸í•œ í„¸**")
        c2.markdown("ğŸ¸ **ì–‡ì€ ë¼ì¼“ ì¤„**")
        c3.markdown("ğŸ•¸ **ë³µì¡í•œ ê±°ë¯¸ì¤„**")
